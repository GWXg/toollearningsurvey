# A Survey on Tool Learning with LLMs: Frameworks, Components, Paradigms and Strategies

### Survey Overview
As the integration of Large Language Models (LLMs) with external tools has become a core direction for expanding model capabilities, the field of "LLM Tool Learning" has seen a surge of research. However, it currently faces pain points including **fragmented resources, unclear technical contexts, and inconsistent paradigm classifications**.

The core value of this survey and its supporting repository lies in:
- **Addressing domain fragmentation**: Establishing a unified "Human-LLM-Tool-Environment" framework to clarify the core components and interaction logic of tool learning;
- **Systematically organizing technical contexts**: Categorizing and integrating research progress across key modules (e.g., tool invocation paradigms, adaptive fine-tuning strategies, evaluation benchmarks);
- **Providing reusable resources**: Offering structured CSV tables and visual charts to help researchers quickly locate target papers, reuse benchmark datasets, and map the domain's evolutionary path.

Whether youâ€™re a new researcher or a practitioner needing to synthesize field progress, this survey and repository will help you efficiently grasp the core of LLM tool learning.


<img width="609" height="405" alt="image" src="https://github.com/user-attachments/assets/bf7a4a91-da48-46c8-9491-6653e68cac11" />

<img width="725" height="359" alt="image" src="https://github.com/user-attachments/assets/6a190167-f3e3-4c63-a0c9-3dbbc47a5af7" />

## ðŸ“… Upcoming Updates (TODO)
We are gradually uploading supporting resources for this survey. The upcoming update plan is as follows:
1. **Improve CSV tables in the `data` directory**  
   Supplement paper metadata in `tool_learning_papers.csv` and benchmark dataset details in `dataset_table.csv`; Expected completion: Mid-December 2025
2. **Add visual charts to the `figures` directory**  
   Supplement tool learning paradigm evolution diagrams and field paper quantity trend charts; Expected completion: Late December 2025
3. **Complete paper & resource links**  
   Add official paper links and corresponding code repository addresses; Expected completion: End of December 2025
4. **Add prompt templates & experimental resources**  
   Add tool invocation prompt templates and minimal code examples for instruction fine-tuning experiments; Expected completion: Early January 2026

The CSV-format summary tables for the survey are currently being prepared and will be uploaded shortly.
